\documentclass[12pt, a4paper]{article}

% --- PACKAGES ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{authblk}
\usepackage{abstract}
\usepackage{newtxtext,newtxmath}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{titling}
\usepackage{enumitem}
\usepackage{lastpage}
\usepackage{caption}
\usepackage{float}
\usepackage{microtype}
\usepackage{etoolbox}

\usepackage[hang]{footmisc}
\usepackage[most]{tcolorbox}
\usepackage[dvipsnames,table,xcdraw]{xcolor}
\usepackage[colorlinks=true, linkcolor=NavyBlue, citecolor=NavyBlue, urlcolor=NavyBlue]{hyperref}

% --- GEOMETRY AND LAYOUT ---
\geometry{
  a4paper,
  margin=1in,
  top=0.8in,
  bottom=1in
}
\setlength{\footnotemargin}{1em}
\onehalfspacing
\setlength{\parskip}{0.2em}

% --- TITLE SETUP ---
\preauthor{\begin{center}\large}
\postauthor{\par\end{center}}
\setlength{\affilsep}{-0.3em}
\setlength{\droptitle}{-4em}

\title{\textbf{Cognitive Sovereignty in Algorithmic Societies}\\
    \large A Methodological Framework for Reclaiming Human Agency\\
    \vspace{1.5em}
    \small MMG Technical Report No. 3: \texttt{MMG-TR-003} \\
    \small \textbf{Status:} \textit{Policy Framework / Ethical Standard}}

\author{Djeff Bee\thanks{Correspondence: \href{mailto:info@meaningfulness.com.au}{info@meaningfulness.com.au}}}
\affil{\textit{Principal Architect, Meaningfulness Media Group}}
\date{\today}

% --- DOCUMENT BEGINS ---
\begin{document}

\maketitle
\vspace{-1em}

% --- COPYRIGHT FOOTER ---
\thispagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\cfoot{
    \footnotesize Copyright \copyright\ 2026 Meaningfulness Media Group. All Rights Reserved. \\
    Page \thepage\ of \pageref{LastPage}
}

% --- ABSTRACT ---
\begin{abstract}
\noindent
As predictive algorithms reach hyper-fidelity, the functional definition of human agency faces an existential reductionist threat. Building on the metric of \textbf{Agency Depth ($D_A$)} established in \cite{TR002}, this report models the modern "Attention Economy" as an \textbf{Adversarial Optimization System}. We argue that digital platforms maximize revenue by systematically collapsing the user's \textbf{Unpredictability Horizon}, effectively rendering human agents \textbf{Computationally Reducible} to satisfy the requirements of behavioral futures markets.

We identify specific attack vectors—\textbf{Script Injection}, \textbf{Temporal Collapse}, and \textbf{Model Distortion}—that bypass System 2 deliberation. We classify this impact as \textbf{Ontological Harm}: a systemic injury not merely to the user's data privacy, but to their functional capacity for self-authorship and causal origin. To counter this, we propose the \textbf{"Right to Remain Incomputable"} as a foundational digital human right. We operationalize this right through the \textbf{Authorship Transparency Statement (ATS)} and the architectural mandate for \textbf{Cognitive Sanctuaries}, providing a regulatory blueprint for preserving human sovereignty in an age of automated determinism.
\end{abstract}

\vspace{1em}
\noindent \textbf{Keywords:} Cognitive Sovereignty, Adversarial Optimization, Attention Economy, Ontological Harm, Agency Depth, Script Injection, Computational Inequality, Surveillance Capitalism, ATS Framework.

% --- HEADER SETTINGS ---
\newpage
\pagestyle{fancy}
\thispagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\footnotesize \texttt{MMG-TR-003}}
\fancyhead[R]{\footnotesize Section \thesection}
\cfoot{
    \footnotesize Copyright \copyright\ 2026 Meaningfulness Media Group. All Rights Reserved. \\
    Page \thepage\ of \pageref{LastPage}
}
\renewcommand{\headrulewidth}{0.4pt}



% --- SECTION 1 ---
\section{Introduction: The Crisis of Reducibility}

In our preceding technical reports, we established the physical and logical foundations of human freedom. \cite{TR001} demonstrated that the future of a complex system is \textbf{Informationally Inaccessible} to any physically embedded observer, shielding the agent from fatalism. \cite{TR002} formalized the internal mechanism of this shield as \textbf{Agency Depth ($D_A$)}—the capacity of a self-modeling system to maintain an \textbf{Unpredictability Horizon} through recursive deliberation.

However, the possession of a capacity does not guarantee its retention. We now face a socio-technical landscape where the primary economic engines—Digital Platforms and Generative AI—are structurally incentivized to collapse that capacity. This report argues that the "Meaning Crisis" of the 21st century is not a philosophical accident, but the successful output of an industrial-scale effort to render the human agent \textbf{Computationally Reducible}.

\subsection{The Economic Imperative: Prediction Requires Reduction}
The business model of the modern internet, often termed \textit{Surveillance Capitalism} \citep{zuboff2019}, relies on the extraction of "behavioral surplus" to trade in futures markets of human action. The value of these futures correlates directly with the certainty of the prediction.

Therefore, the platform's objective function is mathematically diametric to the user's sovereignty:
\begin{itemize}
    \item \textbf{The Sovereign Agent} seeks to maximize $D_A$ (Agency Depth), expanding their Unpredictability Horizon to generate novel, self-authored futures.
    \item \textbf{The Algorithmic Platform} seeks to minimize $D_A$, shrinking the user's horizon to ensure they execute the "High-Probability" path (e.g., clicking the ad, sharing the rage-bait).
\end{itemize}

This dynamic is not merely competitive; it is \textbf{Adversarial Optimization}. To maximize revenue, the system must act as a \textbf{Reductionist Pressure}, actively suppressing user complexity to smooth out the variance of human behavior. The algorithm does not just "predict" the user; it "grooms" the user into a shape that is easier to predict.

\subsection{Redefining Harm: From Content to Ontology}
Current regulatory frameworks, such as the EU AI Act \citep{euai2021}, predominantly focus on \textbf{Content Harm} (e.g., hate speech, misinformation, bias). While necessary, this approach is insufficient. It treats the symptom (bad data) while ignoring the systemic injury (the erosion of the processor).

We introduce the category of \textbf{Ontological Harm}. This is defined as the structural degradation of an agent's functional capacity to self-model and originate causal chains. Even if a feed consists entirely of "safe," distinct, and pleasant content (e.g., infinite entertainment), if its delivery mechanism bypasses the user's System 2 deliberation and collapses their \textbf{Temporal Horizon ($T_h$)} to zero, it inflicts Ontological Harm. It effectively "downgrades" the human \citep{harris2019} from a Sovereign Cause to a Reducible Endpoint.



% --- SECTION 2 ---
\section{Threat Model: The Mechanics of Reduction}

To protect Cognitive Sovereignty, we must map the specific attack vectors utilized by algorithmic systems to dismantle Agency Depth. We utilize the internal vectors established in \cite{TR002}—\textit{Temporal Horizon} ($T_h$), \textit{Counterfactual Width} ($C_w$), and \textit{Model Fidelity} ($R_m$)—to categorize these threats. We argue that modern platform architecture performs an \textbf{Adversarial Coupling} with the human nervous system to bypass the Incomputability Firewall.

\subsection{Attack on Temporal Horizon ($T_h$): Temporal Dysregulation}
The \textbf{Temporal Horizon} is the agent’s capacity to simulate consequences across time. High $T_h$ facilitates teleological (purposeful) planning, while low $T_h$ forces the agent into immediate, reactive loops.

\begin{itemize}
    \item \textbf{Mechanism:} Removal of "Stopping Cues" \citep{alter2017} through Infinite Scroll and Autoplay, combined with Variable Ratio Reinforcement.
    \item \textbf{System State:} By providing a continuous stream of high-salience stimuli, the system denies the agent the "Deliberative Latency" required to shift from System 1 (Reactive) to System 2 (Deliberative) processing.
    \item \textbf{Result:} The agent experiences a state of \textbf{Temporal Collapse}. When the window of decision-making is compressed into sub-second intervals, the agent becomes technically indistinguishable from a simple input-output machine. In this state, the agent is 100\% predictable and therefore loses Process Sovereignty.
\end{itemize}

\subsection{Attack on Model Fidelity ($R_m$): Epistemic Sabotage}
\textbf{Model Fidelity} measures the accuracy of the agent’s internal simulation relative to the causal manifold. 

\begin{itemize}
    \item \textbf{Mechanism:} Algorithmic Curation (Filter Bubbles) and "Outrage-as-Metric." 
    \item \textbf{System State:} The optimizer prioritizes engagement-maximizing data (often high-entropy/falsehood) over accuracy-maximizing data. This creates a \textbf{Predictive Error Bias} in the agent’s internal simulator.
    \item \textbf{Result:} The agent’s world-model becomes \textbf{Decoupled from Reality}. If an agent is solving for a "hallucinated" state-space (e.g., conspiracy-driven heuristics), their Effective Agency ($A_e$) collapses. The agent remains phenomenologically "free" to choose, but their choices are causally impotent, effectively neutralizing their impact on the manifold.
\end{itemize}

\subsection{Attack on Counterfactual Width ($C_w$): Causal Outsourcing}
\textbf{Counterfactual Width} is the resolution of the agent’s "Search Space"—the ability to simulate multiple alternative futures before acting.

\begin{itemize}
    \item \textbf{Mechanism:} Predictive Nudging, "Smart" Replies, and Pre-computed Choices.
    \item \textbf{The Script Injection Attack:} By predicting the agent's next action and offering it as a "frictionless" path, the system performs an \textbf{External Override} of the agent's internal deliberation. 
    \item \textbf{Result:} The agent is incentivized to outsource the metabolic work of "choosing" to the external model. This leads to **Script-Dependency**. Over time, the agent's capacity to generate non-linear, novel trajectories (Incomputability) atrophies. The "Weaver" becomes a "Peripheral," executing pre-written scripts for the sake of efficiency.
\end{itemize}



% --- SECTION 3 ---
\section{Computational Inequality: The New Class Divide}

The erosion of Agency Depth is not distributed uniformly across the global population. We identify an emerging \textbf{Computational Inequality}: a socio-technical divide where sovereignty is no longer a universal baseline, but a luxury determined by an individual’s resistance to reduction. This divide represents a shift from wealth-based inequality to \textbf{Autonomy-based Stratification}.

\subsection{The Reducible Subject: Regimes of High Extraction}
The Reducible Class comprises individuals operating under high "Reductionist Pressure" with minimal "Thermodynamic Scaffolding" (to be detailed in \cite{TR004}). 

\begin{itemize}
    \item \textbf{Environment:} High-frequency exposure to engagement-optimized feeds, reliance on algorithmic management (e.g., Gig Economy platforms), and lack of "Cognitive Sanctuaries."
    \item \textbf{System State:} These subjects are informationally "Solved." Because their environment provides high-fidelity predictive nudges and low-fidelity world-data, their behavior converges on the system’s predicted mean.
    \item \textbf{Status:} They possess a \textbf{Predictability Coefficient} near 1.0. Their future actions are "decision-available" to the platform’s owners before the subjects themselves enter System 2 deliberation. This is the state of \textbf{Causal Passivity}.
\end{itemize}

\subsection{The Sovereign Subject: Regimes of High Autonomy}
The Sovereign Class possesses the resources to defend their Incomputability Firewall.

\begin{itemize}
    \item \textbf{Environment:} Access to high-resolution "Human-First" education, the ability to opt-out of surveillance (ad-free tiers, privacy-focused hardware), and membership in high-fidelity, in-person social networks.
    \item \textbf{System State:} These subjects utilize technology as an \textbf{Instrumental Tool} rather than an \textbf{Existential Environment}. They maintain high Agency Depth ($D_A$) by deliberately introducing "Deliberative Friction" into their decision loops.
    \item \textbf{Status:} They remain \textbf{Computationally Irreducible}. Their response to an external nudge is non-linear and informed by deep historical integration ($H_i$). They are the "Weavers" of the uncomputed future.
\end{itemize}

\subsection{Systemic Injustice: The Right to Friction}
In traditional political philosophy, freedom is often defined as the absence of physical coercion. In the algorithmic era, we argue that \textbf{Predictive Leverage} is a form of coercion. 

If a system can predict an agent’s behavior with $>95\%$ accuracy and adjust the agent's environment to ensure that prediction is realized, the agent’s "choice" is functionally illusory. Forcing a segment of the population into a state of \textbf{Computational Reducibility}—typically those with the least economic power to resist—is a violation of their ontological dignity. We posit that the preservation of "Friction"—the time and space to remain unpredictable—is the primary civil rights battle of the 2030s.


% --- SECTION 4 ---
\section{Defining Ontological Harm}

To protect the integrity of the human process, we propose a new ethical and regulatory category: \textbf{Ontological Harm}. While current discourse focuses on how algorithms affect what we \textit{know} (misinformation) or how we \textit{feel} (mental health), Ontological Harm addresses how algorithms affect what we \textit{are} as causal origins.

\subsection{A Structural Injury to Agency}
We define Ontological Harm as the systemic degradation of an agent’s functional capacity for self-authorship. Unlike Content Harm, which is an injury to the \textit{data} within the system, Ontological Harm is an injury to the \textbf{Processor}. 

It is the act of rendering a subject structurally less capable of executing the "Resolution" model of time established in \cite{TR001}. When an environment optimizes for the collapse of an agent's $D_A$ (Agency Depth), it technically performs a \textbf{Reductionist Intervention}: it shrinks the Incomputability Firewall until the agent is no longer the Salient Cause of their own future.

\subsection{The Mechanism: Causal Decoupling}
The primary symptom of Ontological Harm is the experience of \textbf{Causal Nihilism}: the subjective conviction that individual effort, deliberation, and choice are obsolete. In systems terms, this is a state of \textbf{Causal Decoupling}.

\begin{itemize}
    \item \textbf{The Predictive Loop:} When an external system (e.g., a highly tuned recommendation algorithm) anticipates an agent's desires and provides immediate "frictionless" gratification, the agent's internal "Deliberation Loop" is bypassed.
    \item \textbf{The Error Spike:} The brain’s predictive machinery relies on "Prediction Errors" to update its world-model ($R_m$). In an environment of perfect algorithmic curation, the delta between "Simulated Expectation" and "Realized Input" approaches zero. 
    \item \textbf{Systemic Shutdown:} If the agent's internal processing consistently fails to produce a divergent outcome (i.e., if the algorithm is always "right"), the system concludes that its internal computation is redundant. This results in the down-regulation of metabolic energy for System 2 processing, manifesting as chronic apathy, depression, and the loss of the "Will to Resolve."
\end{itemize}

\subsection{Learned Helplessness as a Technical Failure}
We argue that the global surge in existential despair is a rational system response to this "Ontological Erasure." When a human agent is treated as a **Reducible Data Node**—where their future is "solved" by a server—they lose the \textbf{Dignity of a Cause}. 

By collapsing the Unpredictability Horizon, the Attention Economy effectively "imprisons" the agent in a digital Block Universe. In this state, the agent is no longer a "Weaver" of the future but a passenger in a pre-written script. Reversing this harm requires more than just "better content"; it requires the restoration of the agent’s \textbf{Agency Depth} through the deliberate re-introduction of complexity and friction.



% --- SECTION 5 ---
\section{Policy Framework: The Sovereignty Standards}

To reverse the trend of "Human Downgrading" \citep{harris2019}, we propose an interdisciplinary regulatory framework centered on the preservation of the Incomputability Firewall. These standards move beyond traditional data privacy—which protects the \textit{record} of the past—to protect the \textbf{Agency Depth} required to resolve the future.

\subsection{Standard 1: The Right to Remain Incomputable}
We propose the codification of the \textbf{"Right to Remain Incomputable"} as a foundational digital human right. 

\begin{itemize}
    \item \textbf{Legal Definition:} The right of a human agent to shield their "Decision-Relevant Degrees of Freedom" from algorithmic extraction and optimization.
    \item \textbf{Regulatory Metric:} Systems \textbf{MUST NOT} utilize predictive models to close the loop on an agent's deliberative process in real-time. If a system's optimization leads to a measurable collapse of a user's Unpredictability Horizon ($H_u$), that system is in violation of Cognitive Sovereignty.
    \item \textbf{Objective:} To shift platform design from "Maximizing Predictability" (Profit) to "Preserving Variance" (Sovereignty).
\end{itemize}

\subsection{Standard 2: The ATS Protocol for Epistemic Integrity}
As established in \cite{TR002}, \textbf{Model Fidelity ($R_m$)} is a physical requirement for effective agency. To maintain $R_m$, an agent must accurately identify the \textbf{Causal Origin} of their informational inputs. 

We advocate for the global adoption of the \textbf{Authorship Transparency Statement (ATS)} \citep{ATS2025}. 
\begin{itemize}
    \item \textbf{The "Bright Line" Requirement:} All digital artifacts must carry a standardized metadata tag disclosing the ratio of human-authored (Sovereign) to AI-generated (Stochastic) content. 
    \item \textbf{Technical Rationale:} Humans utilize different cognitive heuristics when interacting with a fellow Causal Agent (Empathy/Reasoning) vs. a Stochastic Model (Utility). Blurring this line induces a state of \textbf{Epistemic Disorientation}, preventing the agent from successfully calibrating their internal simulator to external reality.
\end{itemize}

\subsection{Standard 3: Designation of Cognitive Sanctuaries}
Analogous to the protection of physical wilderness, we propose the designation of \textbf{Cognitive Sanctuaries}: environments where the "Reductionist Pressure" of the Attention Economy is legally excluded.

\begin{itemize}
    \item \textbf{Architectural Mandate:} In these zones (e.g., schools, public libraries, healthcare facilities), the use of behavioral optimization algorithms, personalized dynamic feeds, and high-frequency "nudging" is prohibited.
    \item \textbf{Thermodynamic Function:} Sanctuaries act as "Entropy Recovery Zones." They provide the low-velocity, high-context informational environment required for the system to rebuild its \textbf{Temporal Horizon ($T_h$)} and metabolic capacity for System 2 deliberation.
    \item \textbf{Digital Implementation:} Operating systems should be required to provide a \textbf{"Sovereign Mode"}—a hardware-level override that disables all non-instrumental algorithmic interventions, allowing the user to inhabit an Island of Stability.
\end{itemize}


% --- SECTION 6 ---
\section{Implementation: Design Ethics for 2030}

The transition to a pro-sovereignty digital ecosystem requires a fundamental shift in engineering metrics. We must move from the optimization of \textit{behavioral extraction} to the optimization of \textbf{Agency-Adjusted Utility}.

\subsection{From Engagement to Agency Depth Yield ($D_A$-Yield)}
The current "North Star" metric for platform success—Time-on-Device (ToD)—is a proxy for the successful collapse of the user’s Unpredictability Horizon. We propose its replacement with \textbf{Agency Depth Yield}.

\begin{itemize}
    \item \textbf{The Metric:} Success should be measured by the degree to which an interaction increases the agent's \textbf{Model Fidelity ($R_m$)} and extends their \textbf{Temporal Horizon ($T_h$)}.
    \item \textbf{The Threshold:} If a user's behavior becomes more statistically predictable (e.g., higher script-dependency) after 1,000 hours of platform usage, the platform is technically "Downgrading" the human component.
    \item \textbf{Engineering Requirement:} Systems should be audited based on their "Irreducibility Score"—the degree to which they empower users to make novel, non-scripted choices that diverge from the platform's predicted mean.
\end{itemize}

\subsection{The Friction Mandate: Safeguarding System 2}
The prevailing UX dogma of "Seamlessness" is often a concealment for \textbf{Reductionist Engineering}. By removing all cognitive barriers, designers ensure that the user remains trapped in System 1 (Reactive) loops. We advocate for the \textbf{Friction Mandate}.

\begin{itemize}
    \item \textbf{Deliberative Gates:} High-consequence actions—such as information sharing, financial commitments, or significant "preference" changes—\textbf{SHOULD NOT} be instantaneous. 
    \item \textbf{Mandatory Latency:} Forging a "Sovereign Choice" requires time. Systems should be required to introduce intentional "Cognitive Decoupling" intervals that force the agent out of the flow of algorithmic nudges and back into a state of deliberation.
    \item \textbf{Transparency of Weights:} Users should have the right to inspect and "veto" the weights used by the system to influence their Counterfactual Width ($C_w$).
\end{itemize}

\subsection{From "Dark Patterns" to "Luminous Design"}
We define \textbf{Luminous Design} as an architectural philosophy that exposes the systemic "Shadows" (TR-001) of every algorithmic intervention.
\begin{itemize}
    \item \textbf{Disclosure Requirement:} Any system performing a "Smart" intervention (e.g., Autocomplete, predictive scheduling) must clearly indicate the \textbf{Prediction Confidence} and provide a "Randomize/Diverge" option to allow the user to break the script.
    \item \textbf{Goal:} To ensure that the machine remains the \textit{Tool} and the human remains the \textit{Architect}.
\end{itemize}


% --- SECTION 7 ---
\section{Conclusion: The Beacon of Order}

The current socio-technical crisis is not merely a failure of content moderation or data privacy; it is a fundamental challenge to the functional integrity of human agency. In this report, we have demonstrated that the \textbf{Attention Economy} operates as an adversarial system that extracts the "Unpredictability Horizon" from its users to satisfy the requirements of behavioral futures markets. By systematically collapsing \textbf{Agency Depth ($D_A$)}, the current digital ecosystem technically "downgrades" the human agent from a Salient Cause to a predictable data point.

We have established three definitive conclusions:
\begin{enumerate}
    \item \textbf{Predictability is the Product:} In a society governed by hyper-resolution predictive models, "Sovereignty" is defined as the state of remaining \textbf{Computationally Irreducible}.
    \item \textbf{Ontological Harm is a Structural Injury:} The systemic reduction of an agent's deliberative capacity is a violation of human dignity that results in \textbf{Causal Nihilism} and the collapse of the "Will to Resolve."
    \item \textbf{Sovereignty Requires Scaffolding:} Reclaiming our status as authors of the future necessitates the codification of new rights, such as the \textbf{"Right to Remain Incomputable,"} and the adoption of technical standards like the \textbf{ATS Protocol}.
\end{enumerate}

The defense of Cognitive Sovereignty is not a call for the rejection of technology, but for the \textbf{Sanctity of the Processor}. We must transition from an era of "Seamless Extraction" to an era of \textbf{Luminous Design}—where technology acts as "Cognitive Scaffolding" that expands, rather than shrinks, the human context window.

The \textbf{Meaningfulness Media Group} and the planned \textbf{Meaningfulness Foundation} provide the "Beacon of Order" required to navigate this transition. By defining the standards of agency and the protocols of meaningful connection \citep{TR007}, we ensure that in a world of infinite compute, the human remains the only part of the system that cannot be modeled away. We are the weavers of an uncomputed future; let us ensure the pattern is our own.

% --- BIBLIOGRAPHY ---
\newpage
\fancyhf{}
\fancyhead[L]{\footnotesize \texttt{MMG-TR-003}}
\fancyhead[R]{\footnotesize References}
\cfoot{
    \footnotesize Copyright \copyright\ 2026 Meaningfulness Media Group. All Rights Reserved. \\
    Page \thepage\ of \pageref{LastPage}
}
\renewcommand{\headrulewidth}{0.4pt}

\begin{thebibliography}{99}

\bibitem[Alter(2017)]{alter2017}
Alter, A. (2017). \textit{Irresistible: The Rise of Addictive Technology and the Business of Keeping Us Hooked}. Penguin Press.

\bibitem[Bee(2025)]{ATS2025}
Bee, D. (2025). \textit{Authorship Transparency Statement (ATS) Framework v1.0}. Meaningfulness Media Group. Protocol ID: \texttt{ATS-FRAMEWORK-1.0}.

\bibitem[Bee(2026a)]{TR001}
Bee, D. (2026). \textit{The Illusion of Fatalism: Distinguishing Causal Determinism from Pre-Destination in Complex Systems}. MMG Technical Report No. 1: \texttt{MMG-TR-001}.

\bibitem[Bee(2026b)]{TR002}
Bee, D. (2026). \textit{Functional Agency in Physical Systems: Defining Free Will via Computational Irreducibility}. MMG Technical Report No. 2: \texttt{MMG-TR-002}.

\bibitem[Bee(2026c)]{TR004}
Bee, D. (2026). \textit{The Socio-Technical Foundations of Agency}. MMG Technical Report No. 4: \texttt{MMG-TR-004} [Forthcoming].

\bibitem[Bee(2026d)]{TR007}
Bee, D. (2026). \textit{The Meaningfulness Protocol}. MMG Technical Report No. 7: \texttt{MMG-TR-007} [Forthcoming].

\bibitem[European Commission(2021)]{euai2021}
European Commission. (2021). \textit{Proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)}.

\bibitem[Harris(2019)]{harris2019}
Harris, T. (2019). \textit{Human Downgrading}. Center for Humane Technology.

\bibitem[Kahneman(2011)]{kahneman2011}
Kahneman, D. (2011). \textit{Thinking, Fast and Slow}. Farrar, Straus and Giroux.

\bibitem[Merton(1936)]{merton1936}
Merton, R. K. (1936). The Unanticipated Consequences of Purposive Social Action. \textit{American Sociological Review}, 1(6), 894--904.

\bibitem[Newport(2016)]{newport2016}
Newport, C. (2016). \textit{Deep Work: Rules for Focused Success in a Distracted World}. Grand Central Publishing.

\bibitem[O'Neil(2016)]{oneil2016}
O'Neil, C. (2016). \textit{Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy}. Crown.

\bibitem[Postman(1985)]{postman1985}
Postman, N. (1985). \textit{Amusing Ourselves to Death: Public Discourse in the Age of Show Business}. Viking.

\bibitem[Turkle(2011)]{turkle2011}
Turkle, S. (2011). \textit{Alone Together: Why We Expect More from Technology and Less from Each Other}. Basic Books.

\bibitem[Wu(2016)]{wu2016}
Wu, T. (2016). \textit{The Attention Merchants: The Epic Scramble to Get Inside Our Heads}. Knopf.

\bibitem[Zuboff(2019)]{zuboff2019}
Zuboff, S. (2019). \textit{The Age of Surveillance Capitalism}. PublicAffairs.

\end{thebibliography}

% --- APPENDICES ---
\newpage
\appendix
\fancyhf{}
\fancyhead[L]{\footnotesize \texttt{MMG-TR-003}}
\fancyhead[R]{\footnotesize Appendix \thesection}
\cfoot{
    \footnotesize Copyright \copyright\ 2026 Meaningfulness Media Group. All Rights Reserved. \\
    Page \thepage\ of \pageref{LastPage}
}
\renewcommand{\headrulewidth}{0.4pt}

% --- Appendix A ---
\section{Glossary of Socio-Technical Threats}
\label{app:glossary}

\begin{description}
    \item[Adversarial Optimization] A system design philosophy where the platform's objective function (e.g., maximize engagement) is diametrically opposed to the user's objective function (e.g., maximize well-being or agency).
    \item[Agency Depth ($D_A$)] The metric of an agent's internal complexity (defined in TR-002). In this context, it is the resource targeted for extraction by the Attention Economy.
    \item[Cognitive Sovereignty] The right of a human agent to maintain an \textit{Unpredictability Horizon} and to protect their internal deliberative processes from external script injection or manipulation.
    \item[Computational Inequality] The widening gap between the "Sovereign Class" (who can afford to maintain high $D_A$ and privacy) and the "Reducible Class" (whose behavior is algorithmically managed and predicted).
    \item[Ontological Harm] A systemic injury to the agent's capacity for self-authorship. Unlike content harm (seeing something bad), ontological harm degrades the agent's ability to \textit{choose} or \textit{resolve} the future.
    \item[Script Injection] The process by which an algorithmic system introduces a pre-computed heuristic (e.g., a "Smart Reply" or a rage-bait loop) into the user's cognitive stream, bypassing System 2 deliberation.
\end{description}

% --- Appendix B ---
\newpage
\section{The Agency Audit Checklist}
\label{app:audit}

The \textbf{Meaningfulness Media Group} proposes the following diagnostic questions for evaluating the "Sovereignty Compliance" of any digital platform.

\begin{enumerate}
    \item \textbf{Temporal Respect:} Does the platform have natural "Stopping Cues" (pages, chapters), or does it utilize Infinite Scroll?
    \item \textbf{Deliberative Friction:} Does the platform allow for immediate, high-emotion reaction (1-click share), or does it require a "Cooling Off" period for high-stakes actions?
    \item \textbf{Model Fidelity:} Does the algorithm optimize for "Engagement" (often outrage/falsehood) or "Accuracy" (citations/nuance)?
    \item \textbf{Authorship Transparency:} Does the platform clearly distinguish between human-generated content and AI-generated content (via ATS or similar)?
    \item \textbf{Exit Velocity:} Is it easy to leave the platform with your data (Portability), or does the platform rely on "Lock-in" effects to retain users?
\end{enumerate}

\end{document}